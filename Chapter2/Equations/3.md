如果一个神经元的某个weight“学得慢”，可能是因为：
1. 它的参数（上一层的输入）是low-activation的。  
2. 它的输出是饱和的（接近0或1）

# 参数是low-activation的

根据公式四：  
$$
\begin{eqnarray}  \frac{\partial
    C}{\partial w} = a_{\rm in} \delta_{\rm out},
\tag{32}\end{eqnarray}
$$
可知：  
当$$a_{\rm in} \approx 0$$时，$$\partial C / \partial w \approx 0$$
$$a_{\rm in} \approx 0$$即参数来自low-activation的神经元  
$$\partial C / \partial w \approx 0$$即对应的w会"学得慢"。  

# 输出的饱和的  
回顾一下$$\sigma()$$的曲线：  
![](http://windmissing.github.io/images_for_gitbook/mathematics_basic_for_ML/2.png)  

$$
a = \sigma(z)且a接近0或1 \\
\Rightarrow |z|非常大 \\
\Rightarrow \sigma'(z)\approx 0 \\
\Rightarrow b和w的偏导\approx 0 \\
\Rightarrow 学得慢
$$