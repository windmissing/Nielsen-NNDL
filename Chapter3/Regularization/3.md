# 正则化项对计算一个样本的影响  

加入L2正则化项后，计算一个样本的w、b偏导的公式变为：  
$$
\begin{eqnarray} 
  \frac{\partial C}{\partial w} & = & \frac{\partial C_0}{\partial w} + 
  \frac{\lambda}{n} w \tag{88}\\ 
  \frac{\partial C}{\partial b} & = & \frac{\partial C_0}{\partial b}.
\tag{89}\end{eqnarray}
$$
仍用反向传播算法计算$$\frac{\partial C_0}{\partial w}$$和$$\frac{\partial C_0}{\partial b}$$，在更新w和b时把$$\frac{\lambda}{n} w$$考虑进去。  
得：  
$$
\begin{eqnarray} 
  w & \rightarrow & \left(1-\frac{\eta \lambda}{n}\right) w -\eta \frac{\partial
    C_0}{\partial w}. 
\tag{92} \\
b & \rightarrow & b -\eta \frac{\partial C_0}{\partial b}.
\tag{90}\end{eqnarray}
$$

也就是说，w在每次更新前都要成比例地缩小(rescale)。这个rescale的步骤被称为**weights decay**。  


# 正则化项对一次随机梯度计算的影响

一次随机梯度计算会从n个样本中随机选出m个进行计算。  
基于这m个样本的反向传播算法结果一次性更新w和b的公式为：  
$$
\begin{eqnarray} 
  w \rightarrow \left(1-\frac{\eta \lambda}{n}\right) w -\frac{\eta}{m}
  \sum_x \frac{\partial C_x}{\partial w}, 
\tag{93} \\
b \rightarrow b - \frac{\eta}{m} \sum_x \frac{\partial C_x}{\partial b},
\tag{94}\end{eqnarray}
$$

注意：
公式93的**第一项中的分母是n**，不是m。  
不管这一批随机选择了多少个样本，w的recalse的比例是一样的。  

# 正则化的效果

1. 在过拟合的场景中加入正则化：  
正则化明显抑制了过拟合现象。  
2. 在未过拟合的场景中加入正则化：  
测试样本的准确率提高。  
训练样本与测试样本的准确率之间的gap变小。  
3. 正则化的额外好处：  
非正则化时，有时会困于局部最小值点。  
加入正则化以后，不会发生这种情况，每次运行结果基本上相同。  