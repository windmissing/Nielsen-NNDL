# 为什么正则化能抑制过拟合？

通常的解释是：  
正则化 -> weights小 -> 模型复杂度低 -> 对数据的解释更简单 -> 对数据的解释更好  

但作者对这样的解释并不满意，作者认为：  
1. 正则化后效果会更好，所以非常常用。  
2. 目前对“为什么正则化后效果更好”有非常好的解释。  

# 为什么不对b做正则化？

1. 经验表明，对做正则化的效果没有明显提升。  
2. b很大也没有关系，不会导致“x的轻微变化导致a的巨大变化”。  
3. 对b正则化会使计算变复杂。  
4. b很大使得神经元更容易饱和，这是好事。  